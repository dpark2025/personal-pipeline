# Personal Pipeline MCP Server Configuration
# This is the main configuration file for the PP MCP server

server:
  port: 3000
  host: localhost
  log_level: info
  cache_ttl_seconds: 3600
  max_concurrent_requests: 100
  request_timeout_ms: 30000
  health_check_interval_ms: 60000

# Documentation sources configuration
sources:
  # Local file system adapter - for development and testing
  - name: local-docs
    type: file
    base_url: ./docs
    refresh_interval: 5m
    priority: 1
    enabled: true
    timeout_ms: 5000
    max_retries: 2

  # Example Confluence configuration (commented out by default)
  # - name: ops-confluence
  #   type: confluence
  #   base_url: https://your-company.atlassian.net/wiki
  #   auth:
  #     type: bearer_token
  #     token_env: CONFLUENCE_TOKEN
  #   refresh_interval: 1h
  #   priority: 2
  #   enabled: false
  #   timeout_ms: 30000
  #   max_retries: 3

  # Example GitHub configuration (commented out by default)
  # - name: github-docs
  #   type: github
  #   base_url: https://api.github.com/repos/your-org/docs
  #   auth:
  #     type: bearer_token
  #     token_env: GITHUB_TOKEN
  #   refresh_interval: 30m
  #   priority: 3
  #   enabled: false
  #   timeout_ms: 15000
  #   max_retries: 2

# Cache configuration for improved performance
cache:
  enabled: true
  strategy: hybrid  # hybrid, memory_only, redis_only
  memory:
    max_keys: 1000
    ttl_seconds: 3600
    check_period_seconds: 600
  redis:
    enabled: true
    url: redis://localhost:6379
    ttl_seconds: 7200
    key_prefix: 'pp:cache:'
    connection_timeout_ms: 5000
    retry_attempts: 3
    retry_delay_ms: 2000       # Start with 2 second delay
    # Exponential backoff settings - improved for production
    max_retry_delay_ms: 120000  # Max 2 minutes between retries (increased from 30s)
    backoff_multiplier: 2.5     # Slower exponential backoff (increased from 2)
    connection_retry_limit: 5   # Max connection attempts before circuit breaker
  content_types:
    runbooks:
      ttl_seconds: 3600
      warmup: true
    procedures:
      ttl_seconds: 1800
      warmup: false
    decision_trees:
      ttl_seconds: 2400
      warmup: true
    knowledge_base:
      ttl_seconds: 900
      warmup: false

# Embedding configuration for semantic search
embedding:
  enabled: true
  model: sentence-transformers/all-MiniLM-L6-v2
  cache_size: 1000