server:
  port: 3000
  host: localhost
  log_level: info
  cache_ttl_seconds: 3600
  max_concurrent_requests: 100
  request_timeout_ms: 30000
  health_check_interval_ms: 60000
sources:
  - name: confluence-ops
    type: confluence
    base_url: https://your-company.atlassian.net/wiki
    auth:
      type: bearer_token
      token_env: CONFLUENCE_TOKEN
    refresh_interval: 1h
    priority: 1
    enabled: true
    timeout_ms: 30000
    max_retries: 3
  - name: github-docs
    type: github
    base_url: https://api.github.com/repos/your-org/docs
    auth:
      type: bearer_token
      token_env: GITHUB_TOKEN
    refresh_interval: 30m
    priority: 2
    enabled: true
    timeout_ms: 15000
    max_retries: 2
  - name: local-runbooks
    type: file
    base_url: ./runbooks
    refresh_interval: 5m
    priority: 3
    enabled: true
    timeout_ms: 5000
    max_retries: 1
cache:
  enabled: true
  strategy: hybrid
  memory:
    max_keys: 1000
    ttl_seconds: 3600
    check_period_seconds: 600
  redis:
    enabled: true
    url: redis://localhost:6379
    ttl_seconds: 7200
    key_prefix: 'pp:cache:'
    connection_timeout_ms: 5000
    retry_attempts: 3
    retry_delay_ms: 2000       # Start with 2 second delay
    # Exponential backoff settings - improved for production
    max_retry_delay_ms: 120000  # Max 2 minutes between retries (increased from 30s)
    backoff_multiplier: 2.5     # Slower exponential backoff (increased from 2)
    connection_retry_limit: 5   # Max connection attempts before circuit breaker
  content_types:
    runbooks:
      ttl_seconds: 3600
      warmup: true
    procedures:
      ttl_seconds: 1800
      warmup: false
    decision_trees:
      ttl_seconds: 2400
      warmup: true
    knowledge_base:
      ttl_seconds: 900
      warmup: false
embedding:
  enabled: true
  model: sentence-transformers/all-MiniLM-L6-v2
  cache_size: 1000
